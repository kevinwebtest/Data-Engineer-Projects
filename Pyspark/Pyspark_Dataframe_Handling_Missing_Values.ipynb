{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ded0783b",
      "metadata": {
        "id": "ded0783b"
      },
      "source": [
        "### Pyspark Handling Missing Values\n",
        "- Dropping Columns\n",
        "- Dropping Rows\n",
        "- Various Parameter In Dropping functionalities\n",
        "- Handling Missing values by Mean, MEdian And Mode"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NM8Y3ykzA2jE",
        "outputId": "83f08e8c-7541-4c31-98b0-c5a35d5d9140"
      },
      "id": "NM8Y3ykzA2jE",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 45 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 62.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=4f5f16bb413ddd50f0039b32b69cf00b5188d316502f9a1142adb60eaa304972\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "805e7382",
      "metadata": {
        "id": "805e7382"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark=SparkSession.builder.appName('Practise').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "e48ebc07",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e48ebc07",
        "outputId": "a89114ca-721f-4b18-ee01-d388375e0c73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+\n",
            "|     Name| age|Experience|Salary|\n",
            "+---------+----+----------+------+\n",
            "|    Krish|  31|        10| 30000|\n",
            "|Sudhanshu|  30|         8| 25000|\n",
            "|    Sunny|  29|         4| 20000|\n",
            "|     Paul|  24|         3| 20000|\n",
            "|   Harsha|  21|         1| 15000|\n",
            "|  Shubham|  23|         2| 18000|\n",
            "|   Mahesh|null|      null| 40000|\n",
            "|     null|  34|        10| 38000|\n",
            "|     null|  36|      null|  null|\n",
            "+---------+----+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark=spark.read.csv('test2.csv',header=True,inferSchema=True)\n",
        "df_pyspark.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "53ab7bbc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53ab7bbc",
        "outputId": "8040663c-f397-435e-bf0a-3ce32711f2a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- Experience: integer (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "523d3c4e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "523d3c4e",
        "outputId": "1c1a7901-215d-47f4-a69e-4f54d7d5e4c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----------+------+\n",
            "| age|Experience|Salary|\n",
            "+----+----------+------+\n",
            "|  31|        10| 30000|\n",
            "|  30|         8| 25000|\n",
            "|  29|         4| 20000|\n",
            "|  24|         3| 20000|\n",
            "|  21|         1| 15000|\n",
            "|  23|         2| 18000|\n",
            "|null|      null| 40000|\n",
            "|  34|        10| 38000|\n",
            "|  36|      null|  null|\n",
            "+----+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "##drop the columns\n",
        "df_pyspark.drop('Name').show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9c041e07",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c041e07",
        "outputId": "860b4f7c-ae8e-456e-f041-4bca6bb2b624"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+\n",
            "|     Name| age|Experience|Salary|\n",
            "+---------+----+----------+------+\n",
            "|    Krish|  31|        10| 30000|\n",
            "|Sudhanshu|  30|         8| 25000|\n",
            "|    Sunny|  29|         4| 20000|\n",
            "|     Paul|  24|         3| 20000|\n",
            "|   Harsha|  21|         1| 15000|\n",
            "|  Shubham|  23|         2| 18000|\n",
            "|   Mahesh|null|      null| 40000|\n",
            "|     null|  34|        10| 38000|\n",
            "|     null|  36|      null|  null|\n",
            "+---------+----+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "36845e38",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36845e38",
        "outputId": "9eac3323-09de-42bf-8aef-5ca38726d639"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark.na.drop().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "156e41cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "156e41cf",
        "outputId": "7031d840-74e9-46ae-f807-1562028a51a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "### any==how\n",
        "df_pyspark.na.drop(how=\"any\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "e9af0da0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9af0da0",
        "outputId": "b452a8c6-4ff1-404f-cd3e-9b19856ca32c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+\n",
            "|     Name| age|Experience|Salary|\n",
            "+---------+----+----------+------+\n",
            "|    Krish|  31|        10| 30000|\n",
            "|Sudhanshu|  30|         8| 25000|\n",
            "|    Sunny|  29|         4| 20000|\n",
            "|     Paul|  24|         3| 20000|\n",
            "|   Harsha|  21|         1| 15000|\n",
            "|  Shubham|  23|         2| 18000|\n",
            "|   Mahesh|null|      null| 40000|\n",
            "|     null|  34|        10| 38000|\n",
            "+---------+----+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "##threshold\n",
        "df_pyspark.na.drop(how=\"any\",thresh=2).show() #atleast 2 non null value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "787fc949",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "787fc949",
        "outputId": "0d54108e-4608-4f8a-9223-c37eb843ad29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "|     null| 34|        10| 38000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "##Subset\n",
        "df_pyspark.na.drop(how=\"any\",subset=['Experience']).show() #for null in particular column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "72bad9ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72bad9ba",
        "outputId": "6d1a9c18-7dd6-4381-efef-a434622d49f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------------+----------+--------------+\n",
            "|     Name|           age|Experience|        Salary|\n",
            "+---------+--------------+----------+--------------+\n",
            "|    Krish|            31|        10|         30000|\n",
            "|Sudhanshu|            30|         8|         25000|\n",
            "|    Sunny|            29|         4|         20000|\n",
            "|     Paul|            24|         3|         20000|\n",
            "|   Harsha|            21|         1|         15000|\n",
            "|  Shubham|            23|         2|         18000|\n",
            "|   Mahesh|Missing Values|      null|         40000|\n",
            "|     null|            34|        10|         38000|\n",
            "|     null|            36|      null|Missing Values|\n",
            "+---------+--------------+----------+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "### Filling the Missing Value\n",
        "df_pyspark.na.fill('Missing Values',['Salary', 'Age']).show() #replace null with String"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "64e01bb9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64e01bb9",
        "outputId": "f8857b46-92dc-4262-e716-156ab67296f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+\n",
            "|     Name| age|Experience|Salary|\n",
            "+---------+----+----------+------+\n",
            "|    Krish|  31|        10| 30000|\n",
            "|Sudhanshu|  30|         8| 25000|\n",
            "|    Sunny|  29|         4| 20000|\n",
            "|     Paul|  24|         3| 20000|\n",
            "|   Harsha|  21|         1| 15000|\n",
            "|  Shubham|  23|         2| 18000|\n",
            "|   Mahesh|null|      null| 40000|\n",
            "|     null|  34|        10| 38000|\n",
            "|     null|  36|      null|  null|\n",
            "+---------+----+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "b66832fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b66832fd",
        "outputId": "bfa9f393-3584-4f2a-f9ff-9701cf4da4e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- Experience: integer (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "e31190f2",
      "metadata": {
        "id": "e31190f2"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import Imputer\n",
        "\n",
        "imputer = Imputer(\n",
        "    inputCols=['age', 'Experience', 'Salary'], \n",
        "    outputCols=[\"{}_imputed\".format(c) for c in ['age', 'Experience', 'Salary']]\n",
        "    ).setStrategy(\"mean\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "d84c4a3d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d84c4a3d",
        "outputId": "9d4c65e4-cb29-422a-d07a-c217411e7593"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+-----------+------------------+--------------+\n",
            "|     Name| age|Experience|Salary|age_imputed|Experience_imputed|Salary_imputed|\n",
            "+---------+----+----------+------+-----------+------------------+--------------+\n",
            "|    Krish|  31|        10| 30000|         31|                10|         30000|\n",
            "|Sudhanshu|  30|         8| 25000|         30|                 8|         25000|\n",
            "|    Sunny|  29|         4| 20000|         29|                 4|         20000|\n",
            "|     Paul|  24|         3| 20000|         24|                 3|         20000|\n",
            "|   Harsha|  21|         1| 15000|         21|                 1|         15000|\n",
            "|  Shubham|  23|         2| 18000|         23|                 2|         18000|\n",
            "|   Mahesh|null|      null| 40000|         28|                 5|         40000|\n",
            "|     null|  34|        10| 38000|         34|                10|         38000|\n",
            "|     null|  36|      null|  null|         36|                 5|         25750|\n",
            "+---------+----+----------+------+-----------+------------------+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Add imputation cols to df\n",
        "imputer.fit(df_pyspark).transform(df_pyspark).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cd38651",
      "metadata": {
        "id": "8cd38651"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b63a65ae",
      "metadata": {
        "id": "b63a65ae"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2992b6a2",
      "metadata": {
        "id": "2992b6a2"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d995bc12",
      "metadata": {
        "id": "d995bc12"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c17fd913",
      "metadata": {
        "id": "c17fd913"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdf76805",
      "metadata": {
        "id": "cdf76805"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "835812ae",
      "metadata": {
        "id": "835812ae"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "Pyspark Dataframe- Handling Missing Values.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}