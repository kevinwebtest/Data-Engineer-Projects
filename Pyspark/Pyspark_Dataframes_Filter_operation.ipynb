{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5d6364f6",
      "metadata": {
        "id": "5d6364f6"
      },
      "source": [
        "### Pyspark Dataframes\n",
        "- Filter Operation\n",
        "- &,|,==\n",
        "- ~"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Emf803Z_K3Wv",
        "outputId": "f28af06c-5b9c-43c3-8565-8d2ecfa4b472"
      },
      "id": "Emf803Z_K3Wv",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 43 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 55.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=2e78f80cb89bda295228e0e852f89dc03d6333a93aae709a03e89b6c39d5f812\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d8d843e1",
      "metadata": {
        "id": "d8d843e1"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark=SparkSession.builder.appName('dataframe').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7964d064",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7964d064",
        "outputId": "2569787f-926c-42f9-b527-b3ba8dfa24ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark=spark.read.csv('test1.csv',header=True,inferSchema=True)\n",
        "df_pyspark.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0fdbb15",
      "metadata": {
        "id": "e0fdbb15"
      },
      "source": [
        "### Filter Operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c21edffc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c21edffc",
        "outputId": "c464a272-5179-4a6a-ba2b-45e2ab60889e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+------+\n",
            "|   Name|age|Experience|Salary|\n",
            "+-------+---+----------+------+\n",
            "|  Sunny| 29|         4| 20000|\n",
            "|   Paul| 24|         3| 20000|\n",
            "| Harsha| 21|         1| 15000|\n",
            "|Shubham| 23|         2| 18000|\n",
            "+-------+---+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Salary of the people less than or equal to 20000\n",
        "df_pyspark.filter(\"Salary<=20000\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d5a5f3af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5a5f3af",
        "outputId": "dd1d9feb-d9fa-43f8-bce7-7ab8e0def10e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+\n",
            "|   Name|age|\n",
            "+-------+---+\n",
            "|  Sunny| 29|\n",
            "|   Paul| 24|\n",
            "| Harsha| 21|\n",
            "|Shubham| 23|\n",
            "+-------+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark.filter(\"Salary<=20000\").select(['Name','age']).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4bebe963",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bebe963",
        "outputId": "5d42742e-6951-48f9-ce73-39ca7ea2a832"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+------+\n",
            "|   Name|age|Experience|Salary|\n",
            "+-------+---+----------+------+\n",
            "|  Sunny| 29|         4| 20000|\n",
            "|   Paul| 24|         3| 20000|\n",
            "| Harsha| 21|         1| 15000|\n",
            "|Shubham| 23|         2| 18000|\n",
            "+-------+---+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark.filter(df_pyspark['Salary']<=20000).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "26f76ee1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26f76ee1",
        "outputId": "c52f326c-2194-48b8-cfd8-b94512cbb137"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+----------+------+\n",
            "|   Name|age|Experience|Salary|\n",
            "+-------+---+----------+------+\n",
            "|  Sunny| 29|         4| 20000|\n",
            "|   Paul| 24|         3| 20000|\n",
            "| Harsha| 21|         1| 15000|\n",
            "|Shubham| 23|         2| 18000|\n",
            "+-------+---+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark.filter((df_pyspark['Salary']<=20000) & \n",
        "                  (df_pyspark['Salary']>=15000)).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5df3d5ab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5df3d5ab",
        "outputId": "bd9b589a-5bdf-4c9b-cf4f-ee56e6d74b6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark.filter(~(df_pyspark['Salary']<=20000)).show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "Pyspark Dataframes- Filter operation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}